<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="论文阅读：Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding"/>




  <meta name="keywords" content="Paper Reading," />





  <link rel="alternate" href="/default" title="zhzw" >




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://example.com/2022/05/07/paper-20220506/"/>


<meta name="description" content="Bridging Pre-trained Models and Downstream Tasks for Source Code UnderstandingMotivation如果要从零开始预训练一个模型需要很多时间，本文提供了方法将大型的预训练模型和代码相关的下游任务结合起来。 当前在编程语言相关的下游任务中，预训练模型有一下两个主要的问题：  因为使用的预训练模型是基于自然语言的，但是编程语言">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding">
<meta property="og:url" content="http://example.com/2022/05/07/paper-20220506/index.html">
<meta property="og:site_name" content="zhzw">
<meta property="og:description" content="Bridging Pre-trained Models and Downstream Tasks for Source Code UnderstandingMotivation如果要从零开始预训练一个模型需要很多时间，本文提供了方法将大型的预训练模型和代码相关的下游任务结合起来。 当前在编程语言相关的下游任务中，预训练模型有一下两个主要的问题：  因为使用的预训练模型是基于自然语言的，但是编程语言">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/data_transformation.png">
<meta property="og:image" content="http://example.com/overview.png">
<meta property="article:published_time" content="2022-05-07T14:20:22.000Z">
<meta property="article:modified_time" content="2022-05-07T14:39:52.565Z">
<meta property="article:author" content="ZHAOWEI ZHANG">
<meta property="article:tag" content="Paper Reading">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/data_transformation.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> 论文阅读：Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding - zhzw </title>
  <meta name="generator" content="Hexo 6.1.0"></head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">zhzw</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          论文阅读：Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding
        
      </h1>

      <time class="post-time">
          May 07 2022
      </time>
    </header>



    
            <div class="post-content">
            <h1 id="Bridging-Pre-trained-Models-and-Downstream-Tasks-for-Source-Code-Understanding"><a href="#Bridging-Pre-trained-Models-and-Downstream-Tasks-for-Source-Code-Understanding" class="headerlink" title="Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding"></a><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.02268.pdf">Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding</a></h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>如果要从零开始预训练一个模型需要很多时间，本文提供了方法将大型的预训练模型和代码相关的下游任务结合起来。</p>
<p>当前在编程语言相关的下游任务中，预训练模型有一下两个主要的问题：</p>
<ul>
<li>因为使用的预训练模型是基于自然语言的，但是编程语言和自然语言是不同的。</li>
<li>预训练模型有几百万的参数，当应用到特定的数据集中时，可能会有过拟合的风险。</li>
</ul>
<p><img src="/data_transformation.png" alt="data_transformation"></p>
<h2 id="两个假设"><a href="#两个假设" class="headerlink" title="两个假设"></a>两个假设</h2><p>作者提出了两个假设来完成对于模型学习顺序的定义。</p>
<ol>
<li>加强的数据对于模型来说更加困难。</li>
<li>对于多分类问题，减少分类的数量是一个更有效的方案。</li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p><img src="/overview.png" alt="overview"></p>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>使用现有的工具完成代码转换。</p>
<h3 id="课程学习策略"><a href="#课程学习策略" class="headerlink" title="课程学习策略"></a>课程学习策略</h3><ol>
<li>在训练过程中逐渐增加增强过的数据。</li>
<li>计算每个类的难度分数，同一个课程采用相同的难度分数。</li>
</ol>
<h3 id="测试增强"><a href="#测试增强" class="headerlink" title="测试增强"></a>测试增强</h3><p>采用和训练的时候类似的转换方案。</p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/Paper-Reading/">Paper Reading</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2022/05/07/hello-world/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Hello World</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2022/05/07/paper-20220507/">
        <span class="next-text nav-default">论文阅读：文档级别文本简化，数据集，标准以及baseline</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2022
    <span class="footer-author">ZHAOWEI ZHANG.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> and <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
